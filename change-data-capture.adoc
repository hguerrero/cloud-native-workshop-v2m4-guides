== Lab3 - Apache Kafka/Change Data Capture
:experimental:

*Apache Kafka* is the de facto standard for asynchronous event propagation between microservices. *Red Hat AMQ Streams* makes it easy to run Apache Kafka on OpenShift with key features:

- Designed for horizontal scalability
- Message ordering guarantee at the partition level
- Message rewind/replay - Long term storage allows the reconstruction of an application state by replaying the messages

AMQ streams component makes Apache Kafka _OpenShift native_ through the use of powerful operators that simplify the deployment, configuration, management, and use of Apache Kafka on OpenShift.

To respond to business demands quickly and efficiently, you need a way to integrate applications and data spread across your enterprise. Things get challenging, though, when adding a service’s database to the picture: how can you avoid inconsistencies between _Kafka and the database_?

Enter *change data capture* (CDC) and *Debezium*. By capturing changes from the log files of the database, Debezium gives you both reliable and consistent inter-service messaging via Kafka and instant read-your-own-write semantics for services themselves.

=== Goals of this lab

The goal of this lab is to add some stream processing on the _orders_ data that is coming in. We will first configure our MongoDB database to enable CDC, then we will deploy a simple Kafka Cluster where we instantiate the MongoDB Debezium CDC connector to retrieve the orders from the database. Finally we will deploy a Kafka Streams application built on Quarkus that analyzes the data to check for potential frauds. After this lab, you should end up with something like:

image::lab3-goal.png[goal, 700]

Scalability is one of the flagship features of Apache Kafka. It is achieved by partitioning the data and distributing them across multiple brokers. Such data sharding also has a big impact on how clients connect and use the broker. This is especially visible when Kafka is running within a platform like Kubernetes but is accessed from outside of that platform.

https://strimzi.io/[Strimzi] is an open source project that provides container images and operators for running https://developers.redhat.com/videos/youtube/CZhOJ_ysIiI/[Apache kafka].

In this lab, we will use productized and supported versions of the Strimzi and Apache Kafka projects through https://www.redhat.com/en/technologies/jboss-middleware/amq?extIdCarryOver=true&sc_cid=701f2000001OH7TAAW[Red Hat AMQ,window=_blank].

=== 1. Enable Change Data Capture in MongoDB

*Change Data Capture’s MongoDB connector* tracks a _MongoDB replica set_ or a _MongoDB sharded cluster_ for document changes in databases and collections, recording those changes as events in Kafka topics. The MongoDB connector uses MongoDB’s `oplog` to capture the changes, so the connector works only with MongoDB replica sets or with sharded clusters where each shard is a separate replica set. 

We will need to configure our Mongo Database to enable CDC.

1. First, we need to change the deployment from one single node to a `replica set`. To achive this, we will need to change the way our container starts by overriding the _entrypoint command_. 

1. From the terminal window run the following command:
+
[source,sh,role="copypaste"]
----
oc patch dc/order-database -p '{ "spec": { "template": { "spec": { "containers": [ { "name": "order-database", "command": [ "mongod" ], "args": [ "--bind_ip_all", "--replSet", "rs0", "--auth" ] } ] } } } }'
----
+
This will start a new deployment process, wait for the new pod configuration to start by checking the topology view in the OpenShift web console.

1. Click on the *order-database* icon to access the deployment detail
+
image::orderdb-topology.png[order-database topology, 700]

1. Click on *View Logs*
+
image::orderdb-viewlogs.png[order-database view logs, 700]

1. Click on the *Terminal* tab to access the pod
+
image::orderdb-terminal.png[order-database terminal, 700]

1. We will enable CDC by issuing the following commands in the terminal window. First make this the _primary_ replica by executing this command:
+
[source,sh,role="copypaste"]
----
mongo localhost:27017/order <<-EOF
    rs.initiate({
        _id: "rs0",
        members: [ { _id: 0, host: "order-database:27017" } ]
    });
EOF
----
+
You should get the following result back:
+
[source,none,role="copypaste"]
----
MongoDB shell version v4.0.16
connecting to: mongodb://localhost:27017/order?gssapiServiceName=mongodb
Implicit session: session { "id" : UUID("78dbbec9-079f-4356-be1a-f20f19bf434e") }
MongoDB server version: 4.0.16
{ "ok" : 1 }
bye
----

1. Next we need to create an user to access the database as we enabled _authentication_. Create the *admin* user:
+
[source,sh,role="copypaste"]
----
mongo localhost:27017/admin <<-EOF
    db.createUser({ user: 'admin', pwd: 'admin', roles: [ { role: "userAdminAnyDatabase", db: "admin" } ] });
EOF
----
+
You should get the following result back:
+
[source,none,role="copypaste"]
----
MongoDB shell version v4.0.16
connecting to: mongodb://localhost:27017/admin?gssapiServiceName=mongodb
Implicit session: session { "id" : UUID("d600f478-066c-40c2-b0c4-4faa6d07a342") }
MongoDB server version: 4.0.16
Successfully added user: {
        "user" : "admin",
        "roles" : [
                {
                        "role" : "userAdminAnyDatabase",
                        "db" : "admin"
                }
        ]
}
bye
----

1. Now is time to create the debezium user to access our data. Create the *listDatabases* role and the *debezium* user:
+
[source,sh,role="copypaste"]
----
mongo -u admin -p admin localhost:27017/admin <<-EOF
    db.runCommand({
        createRole: "listDatabases",
        privileges: [
            { resource: { cluster : true }, actions: ["listDatabases"]}
        ],
        roles: []
    });
    db.createUser({
        user: 'debezium',
        pwd: 'dbz',
        roles: [
            { role: "readWrite", db: "order" },
            { role: "read", db: "local" },
            { role: "listDatabases", db: "admin" },
            { role: "read", db: "config" },
            { role: "read", db: "admin" }
        ]
    });
EOF
----
+
You should get the following result back:
+
[source,none,role="copypaste"]
----
MongoDB shell version v4.0.16
connecting to: mongodb://localhost:27017/admin?gssapiServiceName=mongodb
Implicit session: session { "id" : UUID("7e53d964-0420-4cef-944d-623bfeee685a") }
MongoDB server version: 4.0.16
{
        "ok" : 1,
        "operationTime" : Timestamp(1582830165, 3),
        "$clusterTime" : {
                "clusterTime" : Timestamp(1582830165, 3),
                "signature" : {
                        "hash" : BinData(0,"69Zr4DaNhiBz+fyTFBEqP2OuIts="),
                        "keyId" : NumberLong("6798202436587618305")
                }
        }
}
Successfully added user: {
        "user" : "debezium",
        "roles" : [
                {
                        "role" : "readWrite",
                        "db" : "order"
                },
                {
                        "role" : "read",
                        "db" : "local"
                },
                {
                        "role" : "listDatabases",
                        "db" : "admin"
                },
                {
                        "role" : "read",
                        "db" : "config"
                },
                {
                        "role" : "read",
                        "db" : "admin"
                }
        ]
}
bye
----

You just enabled the MongoDB database to allow the *Debezium* connector read the transaction log.

=== 2. Deploy the orders simulator app

As we mentioned before, one of the benefits of Apache Kafka is the scalability and high throughput.  To check this features, is difficult to manually test our web application. We need some help. Let's deploy an orders simulator app that will inject some random orders coming from partners.

1. In the terminal issue the following command:
+
[source,none,role="copypaste"]
----
oc new-app -n {{ USER_ID }}-cloudnativeapps --docker-image quay.io/hguerreroo/order-producer:jvm --name=simulator
----

1. Configure the deployment to inject the messaging endpoint `hostname` and `port` using the ConfigMap created by our _AddressSpace_ configuration.
+
[source,sh,role="copypaste"]
----
oc patch dc/simulator -p '{ "spec": { "template": { "spec": { "containers": [ { "name": "simulator", "env": [ { "name": "AMQP_HOST", "valueFrom": { "configMapKeyRef": { "name": "amq-config", "key": "service.host" } } }, { "name": "AMQP_PORT", "valueFrom": { "configMapKeyRef": { "name": "amq-config", "key": "service.port.amqp" } } } ] } ] } } } }' 
----

The application simulator will start sending _orders_ to the `order-service` topic in the background. You can track the orders from the http://coolstore-ui-{{ USER_ID }}-cloudnativeapps.{{ ROUTE_SUBDOMAIN}}[Red Hat Cool Store, window=_blank]!

[NOTE]
====
You can stop the `simulator` any time by scaling the _deployment config_ to zero (0).
====

=== 3. Deploying an Apache Kafka cluster on OpenShift

AMQ streams component uses powerful operators that simplify the deployment, configuration, management, and use of Apache Kafka on Red Hat OpenShift® Container Platform. AMQ Streams is already installed using the following _Operators_ so you don’t need to install it in this lab:

* *Kafka Operator* - Responsible for deploying and managing Apache Kafka clusters within an OpenShift cluster.
* *Topic Operator* - Responsible for managing Kafka topics within a Kafka cluster running within an OpenShift cluster.
* *User Operator* - Responsible for managing Kafka users within a Kafka cluster running within an OpenShift cluster.

The basic architecture of operators in AMQ is seen below:

image::kafka-operators-arch.png[amqstreams, 700]

In this section you will learn how to start a local Kafka cluster.

1. Let's create a **Kafka cluster**. Click *+Add* on the left, on the _From Catalog_ box on the project overview:
+
image::kafka-catalog.png[kafka, 700]

1. Type in `kafka` in the search box, and click on the *Kafka*:
+
image::kafka-create.png[kafka, 700]

1. Click on *Create* and you will enter YAML editor that defines a *Kafka* Cluster. 
+
image::kafka-catalog-create.png[kafkacatalogcreate, 700]

1. Replace the editor content with the following code:
+
[source,none,role="copypaste"]
----
apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: events
spec:
  entityOperator:
    topicOperator: {}
    userOperator: {}
  kafka:
    listeners:
      external:
        type: route
      plain: {}
      tls: {}
    replicas: 3
    storage:
      type: ephemeral
  zookeeper:
    replicas: 3
    storage:
      type: ephemeral
----

1. Click on *Create* to deploy the Kafka cluster.
+
image::kafka-create-detail.png[kafka, 700]

1. Wait for cluster to start it can take a few minutes as the operator will deploy your Kafka cluster infrastructure and related operators to manage it.

Make sure it’s actually done rolling out. Visit the {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-cloudnativeapps[Topology View, window=_blank] to check the new pods. Ensure you get the blue circles!

image::kafka-topology.png[order, 700]


=== 4. Configure MongoDB CDC Connector

For setting up Apache Kafka and Kafka Connect on OpenShift, Red Hat AMQ Streams is used. Here we will deploy and use Kafka Connect S2I (Source to Image). S2I is a framework to build images that take application source code as an input and produce a new image that runs the assembled application as output. 

1. In the same _Operator Details_ page, click the *Kafka Connect* tab.
+
image::kafkaconnects2i.png[kafkaConnect, 700]

1. Click in **Create Kafka Connect* button.
+
image::kafkaconnect-create.png[kafkaconnect-create, 700]

1. Replace the _YAML_ editor content with the following code:
+
[source,none,role="copypaste"]
----
apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaConnect
metadata:
  name: debezium
spec:
  bootstrapServers: 'events-kafka-bootstrap:9092'
  image: 'quay.io/hguerreroo/debezium-connect:1.0.2-mongodb'
  replicas: 1
  jvmOptions:
    gcLoggingEnabled: false
----

1. Click *Create* button to deploy the _Kafka Connect connector_.
+
image::kafkaconnect-detail.png[kafkaconnect-detail, 700]

1. Wait for the default deployment to finish and deploy the first pod.

1. Expose the Kafka Connect REST API.
+
[source,bash,role="copypaste"]
----
oc expose service debezium-connect-api --name kafka-connect
----

1. Create a new *connector config* by calling the `POST` method on the _Kafka Connect API_ to react to changes in the `orders` table called `orders-connector`.
+
[source,bash,role="copypaste"]
----
cat << EOF | curl -X POST -H "Accept:application/json" -H "Content-Type:application/json" `oc get route kafka-connect -o jsonpath='{.spec.host}'`/connectors -d @-
{
  "name": "orders-connector",
  "config": {
    "connector.class": "io.debezium.connector.mongodb.MongoDbConnector",
    "tasks.max" : "1",
    "mongodb.hosts" : "rs0/order-database:27017",
    "mongodb.name" : "dbserver1",
    "mongodb.user" : "debezium",
    "mongodb.password" : "dbz",
    "database.whitelist" : "order",
    "database.history.kafka.bootstrap.servers" : "events-kafka-bootstrap:9092",
    "key.converter" : "org.apache.kafka.connect.json.JsonConverter",
    "key.converter.schemas.enable" : "false",
    "value.converter" : "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable" : "false",
    "transforms" : "extract",
    "transforms.extract.type": "io.debezium.connector.mongodb.transforms.ExtractNewDocumentState"
  }
}
EOF
----

1. Get back to the developer console and click on the *Kafka Topic* tab.
+
image::kafka-topic-tab.png[kafka-topic-tab, 700]

1. Notice the newly created _topics_ Custom Resources. The one named *dbserver1.order.order* is where our events are being sent.
+
image::kafka-topic-order.png[kafka-topic-order, 700]

This will configure the MongoDB connector in the _Kafka Connect cluster_ to start reading the transaction log so we can sent events to the Kafka cluster everytime there is a new order in the system without changing the actual code of our application. This events are now available in the Kafka event bus for other microservices to consume and process.

=== 5. Deploying the Data Processor application based on Kafka Streams

_Data Processor_ provides insights on what is happening in our new *reactive* system. Let's go quickly how the prcessing application works and how is it build on *Quarkus* Java runtimes. Actually the code is pretty simple, under the hood we are using the *Kafka Streams* Quarkus extension. 

Kafka Streams is a client library for building applications and microservices, where the input and output data are stored in Kafka clusters. The Streams API is part of the Apache Project since early versions and enables developers to create distributed processing applications. Kafka streams includes a nice Domain Specific Language (DSL) for most normal operations like _map_, _filter_, _count_, _reduce_, _joins_, among others. However, it also allows you to access the Processor API when needed more complex options.

Let’s deploy the processor app that will receive the information generated by Debezium CDC and process it to:

* Collect the orders summary with information about the *total number of orders* received and the *value* of those orders
* Potential Fraud orders, such as the ones with *FAILED* payment transaction and total mount is _over_ *$250 USD*.

In the terminal issue the following command:

[source,bash,role="copypaste"]
----
oc new-app -n {{ USER_ID }}-cloudnativeapps --docker-image quay.io/hguerreroo/data-processor:jvm --name processor -e KAFKA_HOSTNAME=`oc get kafkas/events -n {{ USER_ID }}-cloudnativeapps -o jsonpath='{.status.listeners[?(@.type=="plain")].addresses[0].host}'`:9092
----

This will deploy the application that will start getting the debezium events, and then processing them to get the statistics from the orders as well as to detect the potetial fraud patterns. Finally it will sent the information to two topics where we will be able to query from our _Dashboard_ application.

Visit the {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-cloudnativeapps[Topology View, window=_blank] to check the new pods. Ensure you get the blue circles!

image::processor-topology.png[processor topology, 700]


=== 6. Deploying the Dashboard web application

The _Dashboard_ applicatioon provides a simple and lean user interface to query the information from the _data processor_ service. This application is built with *Quarkus* runtimes using the *Qute* templating engine. 

Qute is a server side _templating engine_ designed specifically to meet the Quarkus needs. The usage of reflection is minimized to reduce the size of native images. The API combines both the imperative and the non-blocking reactive style of coding.

As part of our _Event-driven* journey_ this web application uses *Server-sent events (SSE)* to dynamically update the dashboard's content. Traditionally, a web page has to send a _request_ to the server to receive new data; that is, the page requests data from the server. With server-sent events, it's possible for a server to send new data to a web page at any time, by _pushing messages_ to the web page. These incoming messages can be treated as Events + data inside the web page. Developing a web application that uses server-sent events is easier than with websockets. 

The Dashboard application will show the metrics collected in _total_ orders and _income_ from orders. We are also including a table with the lates 25 _potential fraud_ orders that FAILED payment and were over $250 USD. 

To deploy the dashboard application:

1. Issue the following command in the terminal window:
+
[source,bash,role="copypaste"]
----
oc new-app -n {{ USER_ID }}-cloudnativeapps --docker-image quay.io/hguerreroo/dashboard:jvm --name dashboard -e KAFKA_HOSTNAME=`oc get kafkas/events -o jsonpath='{.status.listeners[?(@.type=="plain")].addresses[0].host}'`:9092
----

1. Enable external access to the web application with the following command:
+
[source,bash,role="copypaste"]
----
oc expose svc/dashboard
----

This will start the rolling update of the dashboard application. Visit the {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-cloudnativeapps[Topology View, window=_blank] to check the new pods. Ensure you get the blue circles!

image::dashboard-topology.png[dashboard topology, 700]

Click on the *Open URL* icon to access the dashboard.

This will show the _Cool Store Enterprise Application_ dashboard with the insights of your ecommerce business. If the order generator is still running you will start to see the numbers moving up and ocassionally orders being filtered as _potential frauds_ that our risk personal will need to asses manually. 

image::dashboard.gif[dashboard, 700]

Congratulations you finished the *Event-Driven Architecture* module!

=== Summary

In this module, we learned how to develop cloud-native applications using multiple Java runtimes (Quarkus and Spring Boot), Javascript (Node.js) and different datasources (i.e. PostgreSQL, MongoDB) to handle a variety of business use cases which implement real-time _request/response_ communication using REST APIs, high performing cacheable services using *JBoss Data Grid*, event-driven/reactive shopping cart service using messaging brokers and Apache Kafka in *Red Hat AMQ Streams*. Then we implemented the Change Data Capture pattern to generate events from the MongoDB database and in the end, we deployed a Kafka Streams application to process these events to feed insights to a enterprise dashboard.

*Red Hat Middleware* enables enterprise developers to design the advanced cloud-native architecture and develop, build, deploy the cloud-native application on hybrid cloud on the *Red Hat OpenShift Container Platform*. Congratulations!

==== Additional Resources:

* https://developers.redhat.com/topics/event-driven/[Event-driven data management for microservices,window=_blank]
* https://www.redhat.com/en/topics/integration/what-is-event-driven-architecture[What is event-driven architecture?,window=_blank]
* https://www.redhat.com/en/products/integration[Red Hat Integration,window=_blank]
* https://www.redhat.com/en/technologies/jboss-middleware/amq[Red Hat AMQ,window=_blank]
* https://developers.redhat.com/blog/2018/10/29/how-to-run-kafka-on-openshift-the-enterprise-kubernetes-with-amq-streams/[How to run Kafka on OpenShift,window=_blank]
* https://developers.redhat.com/products/amq/hello-world-amq-online-openshift/#fndtn-macos[Hello world for AMQ Online on OpenShfit,window=_blank]
